{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSc_Disseration_Codebase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpyit2tC9YLobFKNgblQML",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arron-The-Analyst/MSc-Dissertation-Coding-Repository/blob/master/MSc_Disseration_Codebase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIuzcTnyaj7"
      },
      "source": [
        "# MSc Dissertation Technical Experiment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsEuR_jWshsW"
      },
      "source": [
        "Step 1: Importing the relevant packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s35RWbhfbhg"
      },
      "source": [
        "# Firstly, let's import the relevant packages that we will be using.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import gc  #If you are running this on a GPU, it is likely you will need a garabage collector\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbgUJ7AafvoB"
      },
      "source": [
        "# Then, we need to import the transformer models from the hugging face index (Source: https://huggingface.co/transformers/index.html)\n",
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pktbe5smVFK"
      },
      "source": [
        "# Let's now import the ALBERT sequence classifier and ALBERT tockensizer, again from the hugging face index (Source: https://huggingface.co/transformers/index.html)\n",
        "%%capture\n",
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer\n",
        "\n",
        "# It is ideal to run this over a GPU, but as most computers do not have a GPU, let us enable this to run on a CPU.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJSVH21azLPw"
      },
      "source": [
        "Step 2: Importing the Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9O6urhhraM-",
        "outputId": "19e1d34c-833d-44f6-dce6-f438fe1ceb95",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Firstly, select the CSV file you wish to run the model over.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6798930-eace-4ebd-aa89-8fa638870947\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e6798930-eace-4ebd-aa89-8fa638870947\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving news.csv to news (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aajAuI6p01L"
      },
      "source": [
        "# Next, we can use pandas to import our real news sources on the Coronavirus.\n",
        "text_data = pd.read_csv(\"news.csv\",header=1) # Note: make sure the csv file is the same as the one you have just uploaded"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK7QaBGPmOSb",
        "outputId": "5486fe06-d4d8-4516-d0b0-0eb858f680c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Let's set out our column names and double check that all our data is present\n",
        "text_data.columns = ['text','target_names','target']\n",
        "text_data.head(10)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target_names</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One patient and five members of staff at a car...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Four councils in north Wales are to go into lo...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Visits to a prison have been stopped after an ...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Police officers in England and Wales are to be...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Students at Aberdeen University have been warn...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I feel as if this pandemic has truly left me w...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Steve Thomas, leader of the council's Labour g...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The World Health Organisation has announced it...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>More than 10 million people have downloaded th...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A third wave of coronavirus is “entirely possi...</td>\n",
              "      <td>Real</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text target_names  target\n",
              "0  One patient and five members of staff at a car...         Real       1\n",
              "1  Four councils in north Wales are to go into lo...         Real       1\n",
              "2  Visits to a prison have been stopped after an ...         Real       1\n",
              "3  Police officers in England and Wales are to be...         Real       1\n",
              "4  Students at Aberdeen University have been warn...         Real       1\n",
              "5  I feel as if this pandemic has truly left me w...         Real       1\n",
              "6  Steve Thomas, leader of the council's Labour g...         Real       1\n",
              "7  The World Health Organisation has announced it...         Real       1\n",
              "8  More than 10 million people have downloaded th...         Real       1\n",
              "9  A third wave of coronavirus is “entirely possi...         Real       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5cqQxswzmJB"
      },
      "source": [
        "Step 3: Set up the tockeniser ALBERT model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y2NT4Pimqji"
      },
      "source": [
        "# Now, we need to tokensize our model which we shall do on a standard ALBERT model. A custom tockenization could have potential of future study.\n",
        "token_maker = AlbertTokenizer.from_pretrained('albert-base-v1')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBWbo6sfnXP2"
      },
      "source": [
        "# Next, let's map this to our own dataset using a straightforward lambda function.\n",
        "df_tokens = list(map(lambda t: ['[CLS]'] + token_maker.tokenize(t)[:510] + ['[SEP]'], text_data['text']))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dadEbefwfxn5"
      },
      "source": [
        "# Transformer models have a maximun input of 512 tokens they can process, so we need to limit the size of our system.\n",
        "max_input = 512"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCDOlU1Qf40O"
      },
      "source": [
        "# Now, we can easily find the index of each tocken using the mapping function\n",
        "index_tokens = list(map(token_maker.convert_tokens_to_ids, df_tokens))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "altytCJLtWlH"
      },
      "source": [
        "# And perform a matrix embedding using the numpy array function.\n",
        "index_matrix = np.array([xi+[0]*(max_input-len(xi)) for xi in index_tokens])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkendYgge0Z"
      },
      "source": [
        "# Keeping it simple we just want to know whether a system believes a news item is Real(1) or Fake(0). \n",
        "# Therefore using a binary classifier is the easiest way to achieve this.\n",
        "target = text_data['target'].values"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ijDag0tmX8"
      },
      "source": [
        "# Let's now create a dictionary which maps our indexs and tokens together.\n",
        "\n",
        "# Create an dictionary of all of words and indicies\n",
        "words = []\n",
        "indices = []\n",
        "\n",
        "# Use the extend function to map the tokens to the words.\n",
        "for l in df_tokens:\n",
        "  words.extend(l)\n",
        "\n",
        "# Use the extend function to map the indexs to the tockens.\n",
        "for i in index_tokens:\n",
        "  indices.extend(i)\n",
        "\n",
        "# Use the zip function and create our two dicitonaries.\n",
        "word_to_ix = dict(zip(words, indices))\n",
        "ix_to_word = dict(zip(indices, words))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcgfzTwkuwDX"
      },
      "source": [
        "# As ALBERT makes use of word embedding we will also need to mask the variables together.\n",
        "mask = [[float(i>0) for i in ii] for ii in index_matrix]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5X5CCfZvPTU"
      },
      "source": [
        "Step 4: Format the data into a tensor so that it can be processed by the ALBERT model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLzWa1aZvDin"
      },
      "source": [
        "# Let's start by setting a small batch size of 5 results. (You can change this value)\n",
        "Batch_Size = 5"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F692sTMwvcYs"
      },
      "source": [
        "# Then we can create a method to load our data into a form which can be processed by Pytorch.\n",
        "def tensor_format(text_data, mask, labels, batch_size):\n",
        "    \n",
        "    X = torch.from_numpy(text_data)\n",
        "    X = X.long()\n",
        "    \n",
        "    mask = torch.tensor(mask)\n",
        "    \n",
        "    y = torch.from_numpy(labels)\n",
        "    y = y.long()\n",
        "    \n",
        "    t_p = data_utils.TensorDataset(X, mask, y)\n",
        "    loader = data_utils.DataLoader(t_p, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    return loader"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZgSoPLlvo1V"
      },
      "source": [
        "# Finally, we can split our data using a classic test-train function on. We have set the default to a 80:20 split.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(index_matrix, target, \n",
        "                                                    test_size=0.2, random_state=42)  \n",
        "\n",
        "train_masks, test_masks, _, _ = train_test_split(mask, index_matrix, \n",
        "                                                       test_size=0.2, random_state=42)\n",
        "\n",
        "training_data = tensor_format(X_train, train_masks, y_train,Batch_Size)\n",
        "testing_data = tensor_format(X_test, test_masks, y_test, Batch_Size)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyCH6rJywPpf",
        "outputId": "d148c274-a44e-4c6e-cac1-6255a53e5368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Let us just run an iteration of our training data to make sure this is working as intended.\n",
        "next(iter(training_data))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[    2,   698,  2041,  ...,     0,     0,     0],\n",
              "         [    2, 13538, 14792,  ...,     0,     0,     0],\n",
              "         [    2,    19,    21,  ...,     0,     0,     0],\n",
              "         [    2,    83,     8,  ...,     0,     0,     0],\n",
              "         [    2,    21,   653,  ...,     0,     0,     0]]),\n",
              " tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
              " tensor([1, 1, 0, 1, 1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNr9qOPuZAt"
      },
      "source": [
        "Step 5: Load and Run the Model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TlijNv3nsFc",
        "outputId": "56265c47-4fb3-4408-f26a-eeb5899233ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# Firstly, let us define our model we shall be running.\n",
        "model = AlbertForSequenceClassification.from_pretrained('albert-base-v1') # Source (https://github.com/google-research/albert)\n",
        "\n",
        "# Then, just quickly check it has loaded in.\n",
        "model"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaWDUp8owxZo"
      },
      "source": [
        "# Let us build a simple method to check the accuracy of our obtained results using the tqdm import.\n",
        "\n",
        "def accuracy(model, dataloader, processor):\n",
        "    tqdm()\n",
        "    model.eval()\n",
        "    correct, num_samples = 0,0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for i, batch in enumerate(tqdm(dataloader)):\n",
        "            token_ids, masks, labels = tuple(t.to(processor) for t in batch)\n",
        "            _, yhat = model(input_ids=token_ids, attention_mask=masks, labels=labels)\n",
        "            predict = (torch.sigmoid(yhat[:,1]) > 0.5).long()\n",
        "            num_samples += labels.size(0)\n",
        "            correct += (predict==labels.long()).sum()\n",
        "            \n",
        " # Save space by deleting uneccessary labels           \n",
        "            del token_ids, masks, labels \n",
        "        gc.collect() \n",
        "        \n",
        " # Return accuracy measure.       \n",
        "        return correct.float()/num_samples*100"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70j2IyGo4Y_D"
      },
      "source": [
        "Step 6: Output the Results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtm7Y5Haw3su"
      },
      "source": [
        "# To start with let us reload our processor.\n",
        "processor = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set the number of times you wish to run the model\n",
        "times_run = 4\n",
        "\n",
        "# We can also use the simple Adam model optimiser to make sure our system is running effectively.\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "lost = []\n",
        "model.to(processor)\n",
        "opt = optim.Adam(model.parameters(), lr=3e-6)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkTJQz4ka5P-",
        "outputId": "2032f728-becc-4258-a840-daf2c8827695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# For every time run, set parameters\n",
        "for times in range(times_run):\n",
        "    model.train()\n",
        "    loss_rate = 0.0\n",
        "    iterate = 0\n",
        "    \n",
        "    # For every batch in the training set, run the optimization.\n",
        "    for i, batch in enumerate(training_data):\n",
        "        iterate += 1\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch)\n",
        "        opt.zero_grad()\n",
        "        loss, yhat = model(input_ids=token_ids, attention_mask=masks, labels=labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        loss_rate  += float(loss.item())\n",
        "         \n",
        "        # Get rid of obselte information.\n",
        "        del token_ids, masks, labels\n",
        "    \n",
        "        # Display results if less than 20%\n",
        "        if not i%20:\n",
        "            print(f'Run Number: {times+1:03d}/{times_run:03d} | '\n",
        "                  f'Batch {i+1:03d}/{len(training_data):03d} | '\n",
        "                  f'Average loss in last iteration: {(loss_rate/iterate):.4f}')\n",
        "            \n",
        "            # Reset values\n",
        "            loss_rate  = 0.0\n",
        "            iterate = 0\n",
        "\n",
        "        # Optional, save RAM and perform another Garabage Collection.\n",
        "        # gc.collect()\n",
        "\n",
        "        # Append lost values to an array.\n",
        "        lost.append(float(loss.item()))\n",
        "    \n",
        "    # Print out current training accuracy after each iteration.\n",
        "    with torch.set_grad_enabled(False):\n",
        "          print(f'\\n Current training accuracy: '\n",
        "              f'{accuracy(model, training_data, processor):.2f}%')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run Number: 001/004 | Batch 001/003 | Average loss in last iteration: 0.8032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3/3 [00:25<00:00,  8.51s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Current training accuracy: 21.43%\n",
            "Run Number: 002/004 | Batch 001/003 | Average loss in last iteration: 0.7600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3/3 [00:25<00:00,  8.47s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Current training accuracy: 28.57%\n",
            "Run Number: 003/004 | Batch 001/003 | Average loss in last iteration: 0.7203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3/3 [00:25<00:00,  8.44s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Current training accuracy: 64.29%\n",
            "Run Number: 004/004 | Batch 001/003 | Average loss in last iteration: 0.6727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3/3 [00:25<00:00,  8.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Current training accuracy: 78.57%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN09sdC9xqqS",
        "outputId": "877959bc-cf35-4dcd-9d8f-e06d4071cb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "  print(f'\\n Final test accuracy:'\n",
        "  f'{accuracy(model, training_data, processor):.2f}%')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3/3 [00:25<00:00,  8.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Final test accuracy:78.57%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whz3xLW47pv9"
      },
      "source": [
        "Step 7: Try to interpret test accuracy as a qualatative measure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDpod6FW8BV_",
        "outputId": "d146cf37-8c0e-4ede-c9c9-b9a03b7a6a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Get the accuracy value and convert from a tensor to a numpy.\n",
        "accuracy_value = accuracy(model, training_data, processor).numpy()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3/3 [00:25<00:00,  8.41s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmS0M_0v8Boo",
        "outputId": "1cccb875-59dd-4d36-c802-d1a89cdea214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Provide a contextual explination of the obtained results.\n",
        "if accuracy_value > 0 and accuracy_value <= 0.24:\n",
        "  print(\"We obtained a training accuracy score of %d\" %accuracy_value + \"%\") \n",
        "  print(\"This indicates that: The model is struggling to distinguish between Real and Fake News Sources on the Coronavirus.\")\n",
        "\n",
        "if accuracy_value >= 0.25 and accuracy_value <=0.49:\n",
        "   print(\"We obtained a training accuracy score of %d\" %accuracy_value + \"%\")\n",
        "   print(\"This indicates that: The Model is underperforming at finding the difference between Real and Fake Sources on the Coronavirus.\")\n",
        "\n",
        "if accuracy_value  >= 0.5 and accuracy_value <=0.75:\n",
        "  print(\"We obtained a training accuracy score of %d\" %accuracy_value + \"%\")\n",
        "  print(\"This indicates that: The Model is performing okay at identifying the difference between Real and Fake Sources on the Coronavirus.\")\n",
        "\n",
        "else: \n",
        "    print(\"We obtained a training accuracy score of %d\" %accuracy_value + \"%\")  \n",
        "    print(\"This indicates that: The Model is confidently and accurately defining Real and Fake News Sources on the Coronvirus.\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We obtained a training accuracy score of 78%\n",
            "This indicates that: The Model is confidently and accurately defining Real and Fake News Sources on the Coronvirus.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}